{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Test Scoring Pipeline and Deploy R Shiny Dashboard App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Now that we have built the machine learning models, stored and deployed them, we can use the models to score new data. \n",
    "\n",
    "In the first part of the notebook we will:\n",
    "\n",
    "* Programmatically get the ID's for the deployment space and model deployments that were created in the **1-model-training** notebook.\n",
    "* Promote assets required for scoring new data into the deployment space.\n",
    "* Create a deployable function which will take raw data for scoring, prep it into the format required for the models and score it.\n",
    "* Deploy the function.\n",
    "* Create the required payload, invoke the deployed function and return predictions.\n",
    "\n",
    "In the second part we will:\n",
    "* Store Shiny assets into the same deployment space.\n",
    "* Deploy Shiny assets as an app and view the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Materials, provided under license. <br>\n",
    "Licensed Materials - Property of IBM. <br>\n",
    "Â© Copyright IBM Corp. 2019,2020. All Rights Reserved. <br>\n",
    "US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs\n",
    "\n",
    "Enter the user's wml credentials, the path to the csv file with raw data to be scored and a list of events to be predicted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "token = os.environ['USER_ACCESS_TOKEN']\n",
    "url= os.environ['RUNTIME_ENV_APSX_URL']\n",
    "\n",
    "wml_credentials = {\n",
    "   \"token\": token,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": url,\n",
    "   \"version\": \"3.0.0\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the location of the csv file with raw customer data that we would like to score for\n",
    "dataset_loc = '/project_data/data_asset/event.csv'\n",
    "dataset_name = os.path.basename(dataset_loc)\n",
    "\n",
    "prediction_events = ['LFE_RELOCATION', 'LFE_HOME_PURCHASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Deployment Space, Deployments and Assets\n",
    "\n",
    "The following code programmatically gets the deployment space and the model deployment details which were created in **1-notebook-training**. \n",
    "We use the space name and default tags that were used when creating the deployments as specified below. If multiple spaces with the same name exist, the code will take the space that was created most recently. Similarly, if multiple deployments within the selected space have the same tag, the most recently created deployment is used.\n",
    "\n",
    "Alternatively, the user can manually enter the space and deployment guid's.\n",
    "\n",
    "The code also promotes some assets into the deployment space, specifically, the dataset with raw data for scoring, the census data if required, the python script file which is used for prepping the data and the metadata that was stored when prepping the data. By promoting these assets into the deployment space, they are available and can be accessed by the deployed function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name = 'life_event_space'\n",
    "\n",
    "dict_model_tag = {}\n",
    "dict_deployment_tag = {}\n",
    "for event_type in prediction_events: \n",
    "    dict_model_tag[event_type] = 'life_event_' + event_type + '_model_tag'\n",
    "    dict_deployment_tag[event_type] = 'life_event_' + event_type + '_deployment_tag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the space we are working in, which is found using the name that were hardcoded in **1-model_training**. If there are multiple spaces with the same name, we take the one that was created most recently. \n",
    "\n",
    "If the user would like to use a different space manually set the space_id.\n",
    "\n",
    "Set the space as the default space for working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_space_details = []\n",
    "l_space_details_created_times = []\n",
    "for space_details in client.spaces.get_details()['resources']:\n",
    "    if space_details['entity']['name'] == space_name:\n",
    "        l_space_details.append(space_details)\n",
    "        l_space_details_created_times.append(datetime.datetime.strptime(space_details['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "        \n",
    "# get the index of the latest created date from the list and use that to get the space_id\n",
    "list_latest_index = l_space_details_created_times.index(max(l_space_details_created_times))\n",
    "space_id = l_space_details[list_latest_index]['metadata']['guid']\n",
    "# set this space as default space\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFE_RELOCATION\n",
      "LFE_HOME_PURCHASE\n"
     ]
    }
   ],
   "source": [
    "for event_type, _ in dict_deployment_tag.items():\n",
    "    print(event_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the deployment id, again, found using the tags that were hardcoded. If there are multiple deployments with the same tag in the same space, we take the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployments_dict = {}\n",
    "for event_type, deployment_tag in dict_deployment_tag.items():\n",
    "    # get the id of the deployments - again, found using the tags that were hardcoded\n",
    "    # if there are multiple deployments with the same tag in the same space, we take the latest\n",
    "    l_deployment_details = []\n",
    "    l_deployment_details_created_times = []\n",
    "    for deployment in client.deployments.get_details()['resources']:\n",
    "        if 'tags' in deployment['entity']:\n",
    "            if deployment['entity']['tags'][0]['value'] == deployment_tag:            \n",
    "                l_deployment_details.append(deployment)\n",
    "                l_deployment_details_created_times.append(datetime.datetime.strptime(deployment['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "\n",
    "    # get the index of the latest created date from the list and use that to get the deployment_id\n",
    "    list_latest_index = l_deployment_details_created_times.index(max(l_deployment_details_created_times))\n",
    "    deployment_id = l_deployment_details[list_latest_index]['metadata']['guid']\n",
    "    model_deployments_dict[event_type] = deployment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use the prep script for getting the raw data into the format required for scoring.\n",
    "\n",
    "Additionally, we also need the prep metadata that was saved as json during the prep for training - this ensures that the user inputs specified for prepping the data for training are the same used for scoring.\n",
    "\n",
    "Finally, we need to add these files into the deployment space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n",
      "Creating data asset...\n",
      "SUCCESS\n",
      "Creating data asset...\n",
      "SUCCESS\n",
      "Creating data asset...\n",
      "SUCCESS\n",
      "Creating data asset...\n",
      "SUCCESS\n",
      "Creating data asset...\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "asset_details_json = client.data_assets.create('training_user_inputs_and_prepped_column_names.json', file_path='/project_data/data_asset/training_user_inputs_and_prepped_column_names.json')\n",
    "asset_details_script = client.data_assets.create('life_event_prep.py', file_path='/project_data/data_asset/life_event_prep.py')\n",
    "# add the census prep script\n",
    "asset_details_census_script = client.data_assets.create('prep_census_data.py', file_path='/project_data/data_asset/prep_census_data.py')\n",
    "# also store the dataset in the deployment space\n",
    "asset_details_dataset = client.data_assets.create(dataset_name, file_path=dataset_loc)\n",
    "# add the census dataset the deployment space\n",
    "asset_details_census_dataset = client.data_assets.create('census_probabilities.csv', file_path='/project_data/data_asset/census_probabilities.csv')\n",
    "# the census prep also requires the customer csv file\n",
    "asset_details_customer_dataset = client.data_assets.create('customer.csv', file_path='/project_data/data_asset/customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------  ----------  ---------  ------------------------------------\n",
      "NAME                                                ASSET_TYPE  SIZE       ASSET_ID\n",
      "customer.csv                                        data_asset  1273147    65bb4970-9f07-4124-906c-32b8cee08c3b\n",
      "training_user_inputs_and_prepped_column_names.json  data_asset  2747       b44d2bb7-1b80-4a01-8e4c-2481fea57349\n",
      "life_event_prep.py                                  data_asset  38104      33cff368-8854-4863-8b39-6be7fe260d7d\n",
      "prep_census_data.py                                 data_asset  8588       b7c30f99-152e-4851-9c42-f6702f4998f1\n",
      "event.csv                                           data_asset  3088316    4d2ac2f2-6086-41c2-8df5-ccdad4c1eb35\n",
      "census_probabilities.csv                            data_asset  127672342  81f28310-2e53-4cac-ad4d-65e2f54d9261\n",
      "--------------------------------------------------  ----------  ---------  ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "client.data_assets.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Deployable Function\n",
    "\n",
    "Functions can be deployed in Watson Machine Learning in the same way models can be deployed. The python client or REST API can be used to send data to the deployed function. Using the deployed function allows us to prepare the data and pass it to the model for scoring all within the deployed function.\n",
    "\n",
    "We start off by creating the dictionary of default parameters to be passed to the function. We get the ID's of all assets that have been promoted into the deployment space. We also add the model deployment ID and space ID  information into the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the guid's of the assets that were stored in the space. Include these in the dictionary of default parameters that are passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_id = asset_details_json['metadata']['guid']\n",
    "prep_id = asset_details_script['metadata']['guid']\n",
    "dataset_id = asset_details_dataset['metadata']['guid']\n",
    "census_dataset_id = asset_details_census_dataset['metadata']['guid']\n",
    "census_prep_id = asset_details_census_script['metadata']['guid']\n",
    "customer_dataset_id = asset_details_customer_dataset['metadata']['guid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_dict = {'dataset_asset_id' : dataset_id, 'metadata_asset_id' : metadata_id, 'census_asset_id' : census_dataset_id, 'customer_asset_id' : customer_dataset_id,\n",
    "                   'census_prep_script_asset_id' : census_prep_id, 'prep_script_asset_id' : prep_id, 'dataset_name' : dataset_name, \n",
    "                   'census_dataset_name' : 'census_probabilities.csv', 'customer_dataset_name' : 'customer.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials[\"instance_id\"] = \"openshift\"\n",
    "ai_parms = {'wml_credentials' : wml_credentials, 'space_id' : space_id,  'assets' : assets_dict, 'model_deployment_id' : model_deployments_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCORING PIPELINE FUNCTION\n",
    "\n",
    "The function below takes new customers to be scored as a payload. It preps the customer raw data, loads the model, executes the model scoring and generates the predictions for the life events. \n",
    "\n",
    "\n",
    "The following rules are required to make a valid deployable function:\n",
    "\n",
    "> * The deployable function must include a nested function named `\"score\"`.\n",
    "> * The score function accepts a list.\n",
    "> * The list must include an array with the name `\"values\"`.\n",
    "> * The score function must return an array with the name `\"predictions\"`, with a list as the value, which in turn contains an array with the name `\"values\". Example: {\"predictions\" : [{'values' : }]}`\n",
    "> * We pass default parameters into the function, credentials and space detail, details of the assets that were promoted into the space and also the model deployment guid.\n",
    "> * The assets are downloaded into the deployment space and imported as variables. The raw data to be scored is then prepared and the function calls the model deployment endpoints to score and return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_pipeline(parms=ai_parms):\n",
    "     \n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "    client = WatsonMachineLearningAPIClient(parms[\"wml_credentials\"])\n",
    "    client.set.default_space(parms['space_id'])\n",
    "\n",
    "    # call the function to download the stored dataset asset and return the path\n",
    "    dataset_path = client.data_assets.download(parms['assets']['dataset_asset_id'], parms['assets']['dataset_name'])\n",
    "    df_raw = pd.read_csv(dataset_path, infer_datetime_format=True, \n",
    "                             parse_dates=['EVENT_DATE'])\n",
    "    \n",
    "    # download the census data \n",
    "    census_dataset_path = client.data_assets.download(parms['assets']['census_asset_id'], parms['assets']['census_dataset_name'])\n",
    "    df_census = pd.read_csv(census_dataset_path)\n",
    "    # download the customer dataset\n",
    "    customer_dataset_path = client.data_assets.download(parms['assets']['customer_asset_id'], parms['assets']['customer_dataset_name'])\n",
    "    df_customer = pd.read_csv(customer_dataset_path)\n",
    "    \n",
    "    # call the function to download the prep script and return the path\n",
    "    prep_script_path = client.data_assets.download(parms['assets']['prep_script_asset_id'], 'prep_data_script.py')\n",
    "    # remove the rest of path and .py at end of file name to get the name of the script for importing\n",
    "    script_name = os.path.basename(prep_script_path).replace('.py', '')\n",
    "    # call the function to downlaod the census prep script and return the path\n",
    "    census_prep_script_path = client.data_assets.download(parms['assets']['census_prep_script_asset_id'], 'census_prep_data_script.py')\n",
    "    # remove the rest of path and .py at end of file name to get the name of the script for importing\n",
    "    census_script_name = os.path.basename(census_prep_script_path).replace('.py', '')\n",
    "    \n",
    "    # call the function to download the prep metadata and return the path\n",
    "    metadata_path = client.data_assets.download(parms['assets']['metadata_asset_id'], 'user_inputs.json')\n",
    "    \n",
    "    def prep(cust_id, sc_end_date):\n",
    "        import requests\n",
    "        import os\n",
    "        # import the prep script that we downloaded into the deployment space\n",
    "        prep_data_script = __import__(script_name)\n",
    "    \n",
    "        with open(metadata_path, 'r') as f:\n",
    "            user_inputs_dict = json.load(f)\n",
    "        \n",
    "        globals().update(user_inputs_dict)\n",
    "        \n",
    "        input_df = df_raw[df_raw['CUSTOMER_ID'] == cust_id]\n",
    "        \n",
    "        scoring_prep = prep_data_script.LifeEventPrep(target_event_type_ids, train_or_score='score',\n",
    "                                 b_use_census_data=b_use_census_data,\n",
    "                                 scoring_end_date=sc_end_date, forecast_horizon=forecast_horizon,\n",
    "                                 observation_window=observation_window,\n",
    "                                 life_event_minimum_target_count=life_event_minimum_target_count,\n",
    "                                 norepeat_months=norepeat_months,cols_to_drop=cols_to_drop)\n",
    "        \n",
    "        prepped_data_dict = scoring_prep.prep_data(input_df, 'score')\n",
    "        \n",
    "        for event_type in target_event_type_ids:\n",
    "            if prepped_data_dict[event_type] is None:\n",
    "                print(\"Data prep filtered out customer data. Unable to score.\", file=sys.stderr)\n",
    "                return None\n",
    "\n",
    "            # handle empty data\n",
    "            if prepped_data_dict[event_type].shape[0] == 0:\n",
    "                print(\"Data prep filtered out customer data. Unable to score.\", file=sys.stderr)\n",
    "                return None\n",
    "        \n",
    "            # don't need to include target variable for scoring\n",
    "            cols_used_for_training[event_type].remove('TARGET')\n",
    "        \n",
    "            # if a column does not exist in scoring but is in training, add the column to scoring dataset\n",
    "            for col in cols_used_for_training[event_type]:\n",
    "                if col not in list(prepped_data_dict[event_type].columns):\n",
    "                    prepped_data_dict[event_type][col] = 0\n",
    "\n",
    "            # if a column exists in scoring but not in training, delete it from scoring dataset\n",
    "            for col in list(prepped_data_dict[event_type].columns):\n",
    "                if col not in cols_used_for_training[event_type]:\n",
    "                    prepped_data_dict[event_type].drop(col, axis=1, inplace=True)\n",
    "\n",
    "            # make sure order of scoring columns is same as training dataset\n",
    "            prepped_data_dict[event_type] = prepped_data_dict[event_type][cols_used_for_training[event_type]]\n",
    "        \n",
    "        if b_use_census_data:\n",
    "            census_script = __import__(census_script_name)\n",
    "            census = census_script.census_data()\n",
    "            prepped_data_dict = census.prep_census(df_census,df_customer,prepped_data_dict,'score')\n",
    "    \n",
    "        return prepped_data_dict\n",
    "    \n",
    "    def score(payload):\n",
    "        import json\n",
    "        \n",
    "        sc_end_date = payload['input_data'][0]['values']\n",
    "        cust_id = payload['input_data'][0]['cust_id']\n",
    "        \n",
    "        prepped_data_dict = prep(cust_id, sc_end_date)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        \n",
    "        for event_type, prepped_data in prepped_data_dict.items():\n",
    "            # handle empty data\n",
    "            if prepped_data is None:\n",
    "                return {\"predictions\" : [{'values' : 'Data prep filtered out customer data. Unable to score.'}]}\n",
    "            elif prepped_data.shape[0] == 0:\n",
    "                return {\"predictions\" : [{'values' : 'Data prep filtered out customer data. Unable to score.'}]}\n",
    "            else:\n",
    "                \n",
    "                scoring_payload = {\"input_data\":  [{ \"values\" : prepped_data.values.tolist()}]}\n",
    "                \n",
    "                response_scoring = client.deployments.score(parms['model_deployment_id'][event_type], scoring_payload)\n",
    "                result[event_type] = response_scoring  \n",
    "        \n",
    "        return {\"predictions\" : [{'values' : result}]}\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Function\n",
    "\n",
    "The user can specify the name of the function and deployment in the code below. As we have previously seen, we use tags in the metadata to allow us to programmatically identify the deployed function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the function and deploy it \n",
    "function_name = 'life_event_scoring_pipeline_function'\n",
    "function_deployment_name = 'life_event_scoring_pipeline_function_deployment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the ID of software specification to be used with the function\n",
    "\n",
    "The Software Specification refers to the runtime used in the Notebook, WML training and WML deployment. It contains details about the runtime platform, framework versions, other packages used and any custom library used in the concerned runtime.\n",
    "\n",
    "Our notebooks use the default_py3.6 software specification. When we deploy our function we want it to have the same software specification as the notebooks. We get the ID of the notebook software specification and include it in the metadata when storing the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_software_spec_id = client.software_specifications.get_uid_by_name(\"default_py3.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '5f2229ae-3079-4164-9f34-1002a62eaff6' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing........\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='a292e075-c419-45b4-922e-14590aaba497'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add the metadata for the function and deployment    \n",
    "meta_data = {\n",
    "    client.repository.FunctionMetaNames.NAME : function_name,\n",
    "    client.repository.FunctionMetaNames.TAGS : [{'value' : 'lfe_scoring_pipeline_function_tag'}],\n",
    "    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: default_software_spec_id, \n",
    "    client.repository.FunctionMetaNames.SPACE_UID: space_id\n",
    "}\n",
    "\n",
    "function_details = client.repository.store_function(meta_props=meta_data, function=scoring_pipeline)\n",
    "\n",
    "function_id = function_details[\"metadata\"][\"guid\"]\n",
    "\n",
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: function_deployment_name,\n",
    "    client.deployments.ConfigurationMetaNames.TAGS : [{'value' : 'lfe_scoring_pipeline_function_deployment_tag'}],\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    client.deployments.ConfigurationMetaNames.SPACE_UID: space_id\n",
    "}\n",
    "\n",
    "# deploy the stored model\n",
    "function_deployment_details = client.deployments.create(artifact_uid=function_id, meta_props=meta_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score New Data\n",
    "\n",
    "Get the guid of the deployed function, create the payload and use the python client to score the data. The deployed function returns the classification prediction along with the probabilities. \n",
    "\n",
    "The payload contains two values. The first is the effective date for scoring. This is the date that the prediction is computed. The scoring observation window and forecast horizon are calculated from this date. The second value contains the ID of the customer who we would like to make the prediction for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'asset': {'href': '/v4/functions/5f2229ae-3079-4164-9f34-1002a62eaff6?space_id=9f2a4065-a067-4951-80a4-8cf2bbdcc32d',\n",
       "   'id': '5f2229ae-3079-4164-9f34-1002a62eaff6'},\n",
       "  'custom': {},\n",
       "  'description': '',\n",
       "  'name': 'life_event_scoring_pipeline_function_deployment',\n",
       "  'online': {},\n",
       "  'space': {'href': '/v4/spaces/9f2a4065-a067-4951-80a4-8cf2bbdcc32d',\n",
       "   'id': '9f2a4065-a067-4951-80a4-8cf2bbdcc32d'},\n",
       "  'space_id': '9f2a4065-a067-4951-80a4-8cf2bbdcc32d',\n",
       "  'status': {'online_url': {'url': 'https://internal-nginx-svc:12443/v4/deployments/a292e075-c419-45b4-922e-14590aaba497/predictions'},\n",
       "   'state': 'ready'},\n",
       "  'tags': [{'value': 'lfe_scoring_pipeline_function_deployment_tag'}]},\n",
       " 'metadata': {'created_at': '2020-07-02T10:50:02.983Z',\n",
       "  'description': '',\n",
       "  'guid': 'a292e075-c419-45b4-922e-14590aaba497',\n",
       "  'href': '/v4/deployments/a292e075-c419-45b4-922e-14590aaba497',\n",
       "  'id': 'a292e075-c419-45b4-922e-14590aaba497',\n",
       "  'modified_at': '2020-07-02T10:50:02.983Z',\n",
       "  'name': 'life_event_scoring_pipeline_function_deployment',\n",
       "  'parent': {'href': ''},\n",
       "  'space_id': '9f2a4065-a067-4951-80a4-8cf2bbdcc32d',\n",
       "  'tags': ['lfe_scoring_pipeline_function_deployment_tag']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_deployment_id = client.deployments.get_uid(function_deployment_details)\n",
    "client.deployments.get_details(scoring_deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'values': {'LFE_RELOCATION': {'predictions': [{'fields': ['prediction',\n",
       "        'probability'],\n",
       "       'values': [[0, [0.8994900976114832, 0.10050990238851679]]]}]},\n",
       "    'LFE_HOME_PURCHASE': {'predictions': [{'fields': ['prediction',\n",
       "        'probability'],\n",
       "       'values': [[0, [0.9683913063113182, 0.03160869368868198]]]}]}}}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_id = 1007\n",
    "payload = [{'values' : \"2018-09-30\", 'cust_id' : cust_id}]\n",
    "\n",
    "payload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n",
    "# score\n",
    "funct_output = client.deployments.score(scoring_deployment_id, payload_metadata)\n",
    "funct_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Shiny App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will complete the steps to deploy a Shiny Dashboard in Cloud Pak for Data. The app can be deployed in a similar way to models and functions, using the watson_machine_learning_client package.\n",
    "\n",
    "All of the files associated with the dashboard are contained in a zip file which is stored in data assets. If the user would like to make changes to the dashboard, they can download the zip from data assets and upload it in the RStudio IDE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_shiny_deployment_name='life_event_prediction_Shiny_App'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the App\n",
    "\n",
    "Create the associated metadata and store the dashboard zip file in the deployment space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Shiny asset...\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Meta_props to store assets in space \n",
    "meta_props = {\n",
    "    client.shiny.ConfigurationMetaNames.NAME: \"Customer_Life_Event_Prediction_Shiny_assets\",\n",
    "    client.shiny.ConfigurationMetaNames.DESCRIPTION: 'Store shiny assets in deployment space' # optional\n",
    "}\n",
    "app_details = client.shiny.store(meta_props, '/project_data/data_asset/customer-life-event-prediction-dashboard.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the App\n",
    "\n",
    "Create the metadata for the Shiny deployment by providing  name, description, R-Shiny options and Hardware specifications. R-Shiny configuration provides options on whom you want to share the dashboard with, they are 1) anyone with the link 2) Authenticated users 3) Collaborators in this deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '44489c45-b91f-4b62-9f7a-951606e3b0ba' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing..........................................\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='de4b830c-0595-4398-83d1-31c677af3002'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deployment metadata.\n",
    "deployment_meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: r_shiny_deployment_name,\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: 'Deploy Customer Life Event Prediction dashboard',\n",
    "    client.deployments.ConfigurationMetaNames.R_SHINY: { 'authentication': 'anyone_with_url' },\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: { 'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "# Create the deployment.\n",
    "app_uid = client.shiny.get_uid(app_details)\n",
    "rshiny_deployment = client.deployments.create(app_uid, deployment_meta_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Shiny App\n",
    "Now that the dashboard is deployed, it can be accessed through the web browser. The app URL can be found by navigating to the deployed app in the deployment space. \n",
    "\n",
    "Open the Navigation Menu, under ***Analytics*** select ***Analytics deployments -> life_event_space -> Deployments -> life_event_prediction_Shiny_App*** to find the dashboard URL.\n",
    "\n",
    "Alternatively, the path for the app URL can be found from the deployment metadata created in the previous cell. This path should be appended to the user's Cloud Pak for Data hostname to get the complete app URL. To get the path, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{HOSTNAME}/v4/deployments/de4b830c-0595-4398-83d1-31c677af3002/r_shiny\n"
     ]
    }
   ],
   "source": [
    "print(\"{HOSTNAME}\"+rshiny_deployment['metadata']['href'] + '/r_shiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
