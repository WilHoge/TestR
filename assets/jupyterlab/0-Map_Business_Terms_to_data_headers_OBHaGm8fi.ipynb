{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Business Terms to Data Headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we programmatically publish a dataset into a catalog and map business terms to the dataset column headers. The business terms and their mappings are specified in a csv file included with the project. The user must first ensure that the catalog exists and the imported business terms have been published.\n",
    "\n",
    "The user can also assign business terms to column headers manually or by using the Data Discovery capability within Cloud Pak for Data. \n",
    "\n",
    "This notebook is optional. The analytics project runs as expected even if this notebook is not used. \n",
    "\n",
    "**Note that as only Admin users can import terms, this notebook should be run by an Admin user only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the rest APIs interactions with WKC\n",
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "import json\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This project contains Sample Materials, provided under license. <br>\n",
    "Licensed Materials - Property of IBM. <br>\n",
    "Â© Copyright IBM Corp. 2019, 2020. All Rights Reserved. <br>\n",
    "US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Catalog\n",
    "\n",
    "The dataset must first be published into a catalog. The catalog must be manually created. Under **Organize** in the navigation menu, select **All Catalogs** and select **New Catalog**. Enter the name for the catalog and the description if necessary and create the catalog. If the user has already created the catalog this step can be skipped and the existing catalog name should be specified in the code cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs\n",
    "\n",
    "The user must enter the following before running the rest of the notebook: \n",
    "1. **host :** host url of the cluster we are working on.\n",
    "2. **uname :** username for user on this cluster.\n",
    "3. **pword :** password for user on this cluster.\n",
    "4. **catalog_name :** Name of the catalog that we would like to publish the csv to. This catalog is created based on the instructions above or an existing catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample input and syntax\n",
    "# host = 'https://xxxxx.com/'\n",
    "# uname = 'admin'\n",
    "# pword = '******'\n",
    "# catalog_name = 'name for the catalog'\n",
    "\n",
    "\n",
    "host = 'https://zen-cpd-zen.apps.ocp43.tec.uk.ibm.com/'\n",
    "uname = 'wilhoge'\n",
    "pword = 'password'\n",
    "catalog_name = 'WJH-catalog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create additional variables. The user does not need to change the code cell below, unless they change the business terms category name or the name of the csv file with mappings.\n",
    "\n",
    "1. **parent_category :** Parent category of all the projects .i.e Industry Accelerators.\n",
    "2. **category_name :** Name of the business term category corresponding to the project.\n",
    "3. **terms_file :** Name of the csv file containing the list of mappings between column headers and business terms.\n",
    "3. **csv_file_to_publish :** Name of the csv files that will be published into the catalog and for which we map business terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_category = \"Industry Accelerators\"\n",
    "category_name = \"Customer Life Event Prediction\"\n",
    "terms_file = \"customer-life-event-prediction-map-terms.csv\" \n",
    "csv_file_to_publish = [\"event.csv\",\"customer.csv\", \"census_probabilities.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"census_probabilities.csv\"** is optional and can be removed if it is not necessary to be used in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a requests session and use the same session throughout the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates requests session and stores in `s`\n",
    "s = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a token and validate the token on this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the cluster with specified username and password and store the access token for future reference\n",
    "wkcURLauth=host+\"icp4d-api/v1/authorize\"\n",
    "\n",
    "# Payload with username and password\n",
    "payload={\n",
    "    \"username\": uname,\n",
    "    \"password\": pword\n",
    "}\n",
    "\n",
    "# Header with json format\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'cache-control': \"no-cache\"\n",
    "    }\n",
    "\n",
    "# Creates a post request with the endpoints specified above in the wkcURLauth variable with payload and header.\n",
    "# When successfully authenticated token is stored in a variable as below\n",
    "# catch error if the specified url is not correct\n",
    "try:\n",
    "    res = s.post(wkcURLauth,headers=headers,json=payload, verify=False)\n",
    "except:\n",
    "    print(\"The below error has occurred. Please check that the hostname entered is correct.\")\n",
    "    raise\n",
    "    \n",
    "if res.status_code == 200:\n",
    "    accessToken=json.loads(res.text)['token']\n",
    "else:\n",
    "    print('The below error has occurred. Please check entered username and password are correct.')\n",
    "    raise ValueError(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is similar to above cell. The above request session requires cookie to be added.\n",
    "\n",
    "wkcURLauth=host+\"v1/preauth/signin\"\n",
    "payload={\n",
    "    \"username\": uname,\n",
    "    \"password\": pword\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'Authorization': \"Bearer \"+accessToken,\n",
    "    'Accept': \"*/*\",\n",
    "    'Cache-Control': \"no-cache\",\n",
    "    'Accept-Encoding': \"gzip, deflate\",\n",
    "    'Content-Length': \"56\",\n",
    "    'Connection': \"keep-alive\",\n",
    "    'cache-control': \"no-cache\"\n",
    "    }\n",
    "res = s.post(wkcURLauth,headers=headers,json=payload, verify=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set catalog cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access the catalogs, catalog cookies have to be set using the below endpoints. These cookies will be stored in the session variable created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below get request stores catalog cookie into the session\n",
    "catalog_cookie=s.get(host+\"catalog/auth/iamid/callback?redirectUrl=/data/catalogs/&context=icp4data\",verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Business Terms to Headers\n",
    "\n",
    "We complete the following steps to map the business terms to column headers:\n",
    "\n",
    "1. Check if the Parent Category, `Industry Accelerators`, and subcategory, `Customer Life Event Prediction`, exists.\n",
    "2. Load the business terms from the `Customer Life Event Prediction` subcategory into a dataframe.\n",
    "3. Publish the specified dataset into the catalog.\n",
    "4. Assign business terms to the dataset column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check Parent Category and Subcategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell fetches all the categories present in the cluster and stores category id of the parent category `Industry Accelerators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint to check all the categories in the server\n",
    "parent_url=host+\"gov/api/categories?limit=100\"\n",
    "# get request to fetch all categories\n",
    "parent_cat=s.get(parent_url,verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parent category id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Category -  Industry Accelerators exists\n"
     ]
    }
   ],
   "source": [
    "# Check if Industry accelerator category exists and load its id into a variable `parent_id`\n",
    "if parent_cat.status_code == 200:\n",
    "    parent_json=json.loads(parent_cat.text)\n",
    "    for i in parent_json['rows']:\n",
    "                if i['metadata']['name']== parent_category:\n",
    "                    print(\"Parent Category - \",parent_category,\"exists\")\n",
    "                    parent_id=i['artifact_id'] \n",
    "    if parent_json['size']==0:\n",
    "        print(\"The below error has occurred. \" + \"Please ensure that parent category '\" + parent_category + \"' exists and The user has sufficient permissions.\")\n",
    "        raise ValueError(parent_cat.text)\n",
    "else:\n",
    "    print(\"The below error has occurred. \" + \"Please ensure that parent category, '\" + parent_category + \"', exists.\")\n",
    "    raise ValueError(parent_cat.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if `Customer Life Event Prediction` subcategory exists within the `Industry Accelerators` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Endpoint to get all the subcategories in Industry Accelerator\n",
    "category_url=host+\"gov/api/categories/children/\"+parent_id+\"?page=1&limit=100\"\n",
    "# get request to fetch all categories\n",
    "subcategory=s.get(category_url,verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category -  Customer Life Event Prediction exists - Passed\n"
     ]
    }
   ],
   "source": [
    "if subcategory.status_code == 200:\n",
    "    subcategory_json=json.loads(subcategory.text)\n",
    "\n",
    "    # Check if required category exists and load its id into a variable `subcategory_id`\n",
    "    for i in subcategory_json['rows']:\n",
    "        if i['metadata']['name']== category_name:\n",
    "            print(\"Category - \",category_name,\"exists - Passed\")\n",
    "\n",
    "            exists_category=True\n",
    "            subcategory_id=i['artifact_id'] \n",
    "else:\n",
    "    print(\"The below error has occurred. \" + \"Please ensure that category, '\" + category_category + \"', exists.\")\n",
    "    raise ValueError(subcategory.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Subcategory Business Terms into Dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all of the terms in the `Customer Life Event Prediction` subcategory and store them in the `df_terms` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a payload for the post request, This payload contains information on size of the terms, source, category and subcategory ids\n",
    "payload={\"size\":300,\"from\":0,\"_source\":[\"artifact_id\",\"metadata.artifact_type\",\"metadata.name\",\"metadata.description\",\"categories\",\"entity.artifacts\"],\"query\":{\"bool\":{\"filter\":{\"bool\":{\"minimum_should_match\":1,\"should\":[{\"term\":{\"categories.primary_category_id\":subcategory_id}},{\"term\":{\"categories.secondary_category_ids\":subcategory_id}}],\"must_not\":{\"terms\":{\"metadata.artifact_type\":[\"category\"]}}}}}}}\n",
    "# create a post request with above payload \n",
    "wf=s.post(host+\"v3/search\",headers=headers,json=payload,verify=False)\n",
    "# it will return all the terms , load these terms into a dataframe\n",
    "wf_json=json.loads(wf.text)['rows']\n",
    "df_terms=json_normalize(wf_json)\n",
    "\n",
    "df_terms=df_terms[['entity.artifacts.global_id','metadata.name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity.artifacts.global_id</th>\n",
       "      <th>metadata.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_9eafe4b4-...</td>\n",
       "      <td>Suspicious Activity Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_9f3e18ce-...</td>\n",
       "      <td>Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_05018075-...</td>\n",
       "      <td>Transaction Status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_7ea14b1b-...</td>\n",
       "      <td>Email Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_6f2ee129-...</td>\n",
       "      <td>Social Media Account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          entity.artifacts.global_id             metadata.name\n",
       "0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_9eafe4b4-...  Suspicious Activity Type\n",
       "1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_9f3e18ce-...                    Street\n",
       "2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_05018075-...        Transaction Status\n",
       "3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_7ea14b1b-...             Email Address\n",
       "4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_6f2ee129-...      Social Media Account"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# terms dataframe looks as below\n",
    "df_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Publish Dataset into Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ID of the catalog that was specified in the user inputs at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog_id for WJH-catalog d5a8cc78-1925-4851-9f64-170c5c01b80f\n"
     ]
    }
   ],
   "source": [
    "## Get catalog that created and its id by providing name of the catalog created, wich should be same as the one entered in the previous cells\n",
    "#catalog_name=catalog_name.value\n",
    "# Create new header for the requests\n",
    "headers = {\n",
    "'Content-Type': \"application/json\",\n",
    "'Authorization': \"Bearer \"+accessToken\n",
    "\n",
    "}\n",
    "\n",
    "# endpoint to get all the catalogs \n",
    "get_catalog=s.get(host+\"v2/catalogs/\",verify=False, headers=headers)\n",
    "\n",
    "\n",
    "## Find the catalog created with specific name and store name and id of it into catalog_name and catalog_id respectively\n",
    "try:\n",
    "    get_catalog_json=json.loads(get_catalog.text)['catalogs']\n",
    "except:\n",
    "    print(\"The below error has occurred. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n",
    "    raise\n",
    "    \n",
    "catalog_id = ''\n",
    "for metadata in get_catalog_json:\n",
    "    if metadata['entity']['name']==catalog_name:\n",
    "        catalog_id=metadata['metadata']['guid']\n",
    "        print(\"catalog_id for\",catalog_name, catalog_id)\n",
    "\n",
    "if catalog_id == '':\n",
    "    print(\"The provided catalog name cannot be found. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n",
    "    raise ValueError(\"Catalog cannot be found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the project id. All project assets can be accessed using this project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id=os.environ['PROJECT_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all existing csv files in the project folder and store the names of these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload \n",
    "payload={\"query\":\"*:*\",\"limit\":200}\n",
    "# endpoint to access all the project assets in the project folder \n",
    "asset_url=host+\"v2/asset_types/asset/search?project_id=\"+project_id\n",
    "get_asset=s.post(asset_url,json=payload,verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get the asset id of the dataset to be published to the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset id of customer.csv : 1a1b31d0-c6f2-4a87-b90f-e98d4b505a07\n",
      "Asset id of event.csv : f5b7c707-e86e-43f5-b512-f82576e9f098\n",
      "Asset id of census_probabilities.csv : f335ff8a-ff27-4326-afbe-312ceb8e925b\n"
     ]
    }
   ],
   "source": [
    "# Get asset ids of all csv files to be published in to the catalog and store the asset ids in an array\n",
    "\n",
    "project_asset_id=[]\n",
    "# Payload to query all project assets\n",
    "payload={\"query\":\"*:*\",\"limit\":200}\n",
    "\n",
    "get_asset=s.post(host+\"v2/asset_types/asset/search?project_id=\"+project_id,json=payload,verify=False, headers=headers)\n",
    "get_asset_json=json.loads(get_asset.text)\n",
    "for j in get_asset_json['results']:\n",
    "    if j['metadata']['name'] in csv_file_to_publish:\n",
    "        print(\"Asset id of\",j['metadata']['name'],\":\",j['metadata']['asset_id'])\n",
    "        project_asset_id.append(j['metadata']['asset_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the asset ID for the dataset, upload the dataset into the catalog using the post request below. Get the new asset ID of the newly published dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSET ID's of the published assets\n",
      "{'customer.csv': 'bae11be4-714f-41c2-96f5-063354784c67', 'event.csv': 'a2149fc6-7996-4788-8044-6eb5d69e76a1', 'census_probabilities.csv': '920bdd6d-3d49-42bf-a2d5-90126e6d247c'}\n"
     ]
    }
   ],
   "source": [
    "print(\"ASSET ID's of the published assets\")\n",
    "# Creates a empty dictionary\n",
    "catalog_asset_ids={}\n",
    "for asset_id in project_asset_id:\n",
    "    #for  each asset in the project , publish them into the catalog \n",
    "    # pyload to publish the asset\n",
    "    payload={\"mode\":0,\"catalog_id\":catalog_id,\"metadata\":{}}\n",
    "    # endpoint to publish asset\n",
    "    asset_publish_url=host+\"v2/assets/\"+asset_id+\"/publish?project_id=\"+project_id\n",
    "    # Post request with endpoint, heaeder and payload\n",
    "    publishasset=requests.post(asset_publish_url,json=payload,headers=headers,verify=False)\n",
    "    # api endpoint returns below text\n",
    "    publishasset_json=json.loads(publishasset.text)\n",
    "    # extract csv file published and its asset id and append it to the dictionary\n",
    "    catalog_asset_ids[publishasset_json['metadata']['name']]=publishasset_json['asset_id']\n",
    "    \n",
    "print(catalog_asset_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assign Business Terms to Column Headers\n",
    "\n",
    "Read in the file with business terms and their associated column headers and view a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_terms=pd.read_csv(\"/project_data/data_asset/\"+terms_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Terms</th>\n",
       "      <th>Column_header</th>\n",
       "      <th>Table</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account Opened Date</td>\n",
       "      <td>DATE_FIRST_ACCOUNT_OPENED</td>\n",
       "      <td>CUSTOMER-LIFE-EVENT-PREDICTION</td>\n",
       "      <td>CUSTOMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Opened Date</td>\n",
       "      <td>DATE_LAST_ACCOUNT_OPENED</td>\n",
       "      <td>CUSTOMER-LIFE-EVENT-PREDICTION</td>\n",
       "      <td>CUSTOMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Account Opened Date</td>\n",
       "      <td>RELATIONSHIP_START_DATE</td>\n",
       "      <td>CUSTOMER-LIFE-EVENT-PREDICTION</td>\n",
       "      <td>CUSTOMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Opened Date</td>\n",
       "      <td>EFFECTIVE_DATE</td>\n",
       "      <td>CUSTOMER-LIFE-EVENT-PREDICTION</td>\n",
       "      <td>CUSTOMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult Household Members</td>\n",
       "      <td>NUMBER_OF_DEPENDENT_ADULTS</td>\n",
       "      <td>CUSTOMER-LIFE-EVENT-PREDICTION</td>\n",
       "      <td>CUSTOMER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Business Terms               Column_header  \\\n",
       "0      Account Opened Date   DATE_FIRST_ACCOUNT_OPENED   \n",
       "1      Account Opened Date    DATE_LAST_ACCOUNT_OPENED   \n",
       "2      Account Opened Date     RELATIONSHIP_START_DATE   \n",
       "3      Account Opened Date              EFFECTIVE_DATE   \n",
       "4  Adult Household Members  NUMBER_OF_DEPENDENT_ADULTS   \n",
       "\n",
       "                            Table      File  \n",
       "0  CUSTOMER-LIFE-EVENT-PREDICTION  CUSTOMER  \n",
       "1  CUSTOMER-LIFE-EVENT-PREDICTION  CUSTOMER  \n",
       "2  CUSTOMER-LIFE-EVENT-PREDICTION  CUSTOMER  \n",
       "3  CUSTOMER-LIFE-EVENT-PREDICTION  CUSTOMER  \n",
       "4  CUSTOMER-LIFE-EVENT-PREDICTION  CUSTOMER  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out below set of codes if the map terms csv has additional spaces which need to be truncated.\n",
    "#map_terms['Column_header']=map_terms['Column_header'].str.strip(' ')\n",
    "#map_terms[\"Business Terms\"]=map_terms[\"Business Terms\"].str.strip(' ')\n",
    "#map_terms[\"File\"]=map_terms[\"File\"].str.strip(' ')\n",
    "#map_terms[\"Table\"]=map_terms[\"Table\"].str.strip(' ')\n",
    "\n",
    "# Specify the name of the table we are working on\n",
    "#map_terms=map_terms[map_terms['Table']==table_name]\n",
    "print(map_terms.shape)\n",
    "map_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity.artifacts.global_id</th>\n",
       "      <th>metadata.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_9eafe4b4-...</td>\n",
       "      <td>Suspicious Activity Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_9f3e18ce-...</td>\n",
       "      <td>Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_05018075-...</td>\n",
       "      <td>Transaction Status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_7ea14b1b-...</td>\n",
       "      <td>Email Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_6f2ee129-...</td>\n",
       "      <td>Social Media Account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          entity.artifacts.global_id             metadata.name\n",
       "0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_9eafe4b4-...  Suspicious Activity Type\n",
       "1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_9f3e18ce-...                    Street\n",
       "2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_05018075-...        Transaction Status\n",
       "3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_7ea14b1b-...             Email Address\n",
       "4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_6f2ee129-...      Social Media Account"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the `df_terms` and `map_terms` dataframes and map each column header to a business term. The code below loops through each file in the catalog and performs the following tasks:\n",
    "\n",
    "1. Create a dataframe with column headers in the catalog and associated business term and term ids.\n",
    "2. Fetch catalog asset id for each csv in the catalog.\n",
    "3. Create a column_info attribute for all the files in the catalog.\n",
    "4. Map column header to the business terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer.csv bae11be4-714f-41c2-96f5-063354784c67\n",
      "1 EDUCATION_LEVEL is mapped to Education Level\n",
      "2 EMPLOYMENT_STATUS is mapped to Employment Status\n",
      "3 GENDER is mapped to Gender\n",
      "4 ANNUAL_INCOME is mapped to Customer Annual Income\n",
      "5 MONTHLY_NET_INCOME is mapped to Customer Annual Income\n",
      "6 MARITAL_STATUS is mapped to Marital Status\n",
      "7 ACQUISITION_COST is mapped to Customer Acquisition Cost\n",
      "8 ADDRESS_HOME_CITY is mapped to Home Address\n",
      "9 ADDRESS_HOME_COUNTRY is mapped to Home Address\n",
      "10 ADDRESS_HOME_POSTAL_CODE is mapped to Home Address\n",
      "11 ADDRESS_HOME_STATE is mapped to Home Address\n",
      "12 GEOGRAPHIC_AREA_HOME is mapped to Home Address\n",
      "13 ADDRESS_HOME_CITY is mapped to Postal Address City\n",
      "14 ADDRESS_MAILING_CITY is mapped to Postal Address City\n",
      "15 ADDRESS_WORK_CITY is mapped to Postal Address City\n",
      "16 ADDRESS_HOME_COUNTRY is mapped to Postal Address Country\n",
      "17 ADDRESS_MAILING_COUNTRY is mapped to Postal Address Country\n",
      "18 ADDRESS_WORK_COUNTRY is mapped to Postal Address Country\n",
      "19 ADDRESS_HOME_POSTAL_CODE is mapped to Postal Code\n",
      "20 ADDRESS_MAILING_POSTAL_CODE is mapped to Postal Code\n",
      "21 ADDRESS_WORK_POSTAL_CODE is mapped to Postal Code\n",
      "22 ADDRESS_HOME_STATE is mapped to Postal Address State\n",
      "23 ADDRESS_MAILING_STATE is mapped to Postal Address State\n",
      "24 ADDRESS_WORK_STATE is mapped to Postal Address State\n",
      "25 ADDRESS_LAST_CHANGED_DATE is mapped to Years At Current Address\n",
      "26 ADDRESS_MAILING_CITY is mapped to Mailing Address\n",
      "27 ADDRESS_MAILING_COUNTRY is mapped to Mailing Address\n",
      "28 ADDRESS_MAILING_POSTAL_CODE is mapped to Mailing Address\n",
      "29 ADDRESS_MAILING_STATE is mapped to Mailing Address\n",
      "30 GEOGRAPHIC_AREA_MAILING is mapped to Mailing Address\n",
      "31 ADDRESS_WORK_CITY is mapped to Work Address\n",
      "32 ADDRESS_WORK_COUNTRY is mapped to Work Address\n",
      "33 ADDRESS_WORK_POSTAL_CODE is mapped to Work Address\n",
      "34 ADDRESS_WORK_STATE is mapped to Work Address\n",
      "35 GEOGRAPHIC_AREA_WORK is mapped to Work Address\n",
      "36 AGE_RANGE is mapped to Date Of Birth\n",
      "37 BIRTH_YEAR is mapped to Date Of Birth\n",
      "38 CONTACT_PREFERENCE is mapped to Preferred Contact Method\n",
      "39 PREFERRED_COMMUNICATION_FORM is mapped to Preferred Contact Method\n",
      "40 CREDIT_SCORE is mapped to Customer Credit Score\n",
      "41 CURRENT_EMPLOYMENT_START_DATE is mapped to Years With Current Employer\n",
      "42 CUSTOMER_BEHAVIOR is mapped to Customer Behavior\n",
      "43 CUSTOMER_ID is mapped to Customer Identifier\n",
      "44 DATE_FIRST_ACCOUNT_OPENED is mapped to Account Opened Date\n",
      "45 DATE_LAST_ACCOUNT_OPENED is mapped to Account Opened Date\n",
      "46 EFFECTIVE_DATE is mapped to Account Opened Date\n",
      "47 RELATIONSHIP_START_DATE is mapped to Account Opened Date\n",
      "48 DATE_FIRST_ACCOUNT_OPENED is mapped to Customer Account\n",
      "49 DATE_LAST_ACCOUNT_OPENED is mapped to Customer Account\n",
      "50 EFFECTIVE_DATE is mapped to Customer Account\n",
      "51 DEATH_YEAR is mapped to Death Date\n",
      "52 DEBT_SERVICE_COVERAGE_RATIO is mapped to Debt Service Coverage Ratio\n",
      "53 FAMILY_SIZE is mapped to Household Members\n",
      "54 GEOGRAPHIC_AREA_HOME is mapped to Postal Address\n",
      "55 GEOGRAPHIC_AREA_MAILING is mapped to Postal Address\n",
      "56 GEOGRAPHIC_AREA_WORK is mapped to Postal Address\n",
      "57 HEAD_OF_HOUSEHOLD_INDICATOR is mapped to Head Of Household Indicator\n",
      "58 HOME_OWNER_INDICATOR is mapped to Household Home Ownership\n",
      "59 HOUSEHOLD_ID is mapped to Household Identifier\n",
      "60 IMPORTANCE_LEVEL_CODE is mapped to Customer Importance\n",
      "61 INFLUENCE_SCORE is mapped to Customer Influencer Score\n",
      "62 INTERNET_BANKING_INDICATOR is mapped to Internet Banking Use Indicator\n",
      "63 LOYALTY_SCORE is mapped to Customer Loyalty Score\n",
      "64 MARKET_GROUP is mapped to Customer Market Segment\n",
      "65 METRIC_NET_PROMOTER_SCORE is mapped to Customer Willingness To Recommend\n",
      "66 REFERRALS_VALUE_CODE is mapped to Customer Willingness To Recommend\n",
      "67 METRIC_SATISFACTION_LEVEL is mapped to Customer Satisfaction\n",
      "68 MONTHLY_HOUSING_COST is mapped to Monthly Housing Cost\n",
      "69 NUMBER_OF_DEPENDENT_ADULTS is mapped to Adult Household Members\n",
      "70 NUMBER_OF_DEPENDENT_CHILDREN is mapped to Children Household Members\n",
      "71 OLDEST_DEPENDENT_ADULT_BIRTH_YEAR is mapped to Oldest Household Adult Birth Year\n",
      "72 OLDEST_DEPENDENT_CHILD_BIRTH_YEAR is mapped to Oldest Household Child Birth Year\n",
      "73 PRIMARY_ADVISOR_ID is mapped to Customer Advisor\n",
      "74 PRIMARY_ADVISOR_ORGANIZATION_ID is mapped to Customer Advisor Organization\n",
      "75 PRIMARY_BRANCH_PROXIMITY is mapped to Primary Branch Proximity\n",
      "76 PRIMARY_SPOKEN_LANGUAGE is mapped to Customer Language\n",
      "77 PRIMARY_WRITTEN_LANGUAGE is mapped to Customer Language\n",
      "78 PROFESSION is mapped to Customer Occupation\n",
      "79 PURSUIT is mapped to Customer Pursuit\n",
      "80 RELATIONSHIP_START_DATE is mapped to Communication Start\n",
      "81 RELATIONSHIP_START_DATE is mapped to Customer Agreement Validity Start\n",
      "82 RELATIONSHIP_START_DATE is mapped to Customer Event Date\n",
      "83 STATUS_DATE is mapped to Customer Event Date\n",
      "84 RETIREMENT_AGE is mapped to Customer Retirement Age\n",
      "85 SATISFACTION_RATING_FROM_SURVEY is mapped to Customer Satisfaction With Communication Rating\n",
      "86 SPECIAL_TERMS_INDICATOR is mapped to Customer Agreement Type\n",
      "87 STATUS is mapped to Customer Status\n",
      "88 STATUS_DATE is mapped to Customer Event Type\n",
      "89 URBAN_CODE is mapped to Postal Address Area Type\n",
      "90 WALLET_SHARE_PERCENTAGE is mapped to Wallet Share\n",
      "91 YOUNGEST_DEPENDENT_ADULT_BIRTH_YEAR is mapped to Youngest Household Adult Birth Year\n",
      "92 YOUNGEST_DEPENDENT_CHILD_BIRTH_YEAR is mapped to Youngest Household Child Birth Year\n",
      "event.csv a2149fc6-7996-4788-8044-6eb5d69e76a1\n",
      "1 EVENT_DATE is mapped to Customer Event Date\n",
      "2 EVENT_TYPE_ID is mapped to Customer Event Type\n",
      "3 CUSTOMER_ID is mapped to Event Customer\n",
      "census_probabilities.csv 920bdd6d-3d49-42bf-a2d5-90126e6d247c\n",
      "1 AGE is mapped to Census Age Range\n",
      "2 BIRTH_PROB is mapped to Census Birth Probability\n",
      "3 DIVORCE_PROB is mapped to Census Divorce Probability\n",
      "4 EDUCATION is mapped to Education Level\n",
      "5 EMPLOYMENT is mapped to Employment Status\n",
      "6 GENDER is mapped to Gender\n",
      "7 INCOME is mapped to Customer Annual Income\n",
      "8 LOCATION is mapped to State Code\n",
      "9 LOCATION is mapped to State Name\n",
      "10 MARITAL_STATUS is mapped to Marital Status\n",
      "11 MARRIAGE_PROB is mapped to Census Marriage Probability\n",
      "12 MIGRATION_PROB is mapped to Census Migration Probability\n"
     ]
    }
   ],
   "source": [
    "# For every file in the map terms csv do the following\n",
    "# Join the csv with specified file name with the published terms to get its term id\n",
    "# drop if any duplicates found to avoid multiple mappings for the same term\n",
    "\n",
    "#map_terms=map_terms[map_terms['File']==file]\n",
    "map_terms=map_terms.sort_values(by=['File','Column_header'])\n",
    "Terms_Headers=pd.merge(map_terms,df_terms,left_on='Business Terms',right_on='metadata.name',how='inner')\n",
    "Terms_Headers=Terms_Headers.drop_duplicates()\n",
    "\n",
    "for file in catalog_asset_ids:#map_terms.File.unique():\n",
    "    # Catalog asset id of the particular csvs\n",
    "    # for each file name in the map_terms if the csv with this file name exists, get its asset_id from the catalog and use the post request publish create column_info attribute\n",
    "    # This column info attribute is necessary to map the busines terms to column to header\n",
    "    \n",
    "    Terms_Headers_new=Terms_Headers[Terms_Headers.File==file.upper().replace(\".CSV\",\"\")].copy()\n",
    "    catalog_asset_id=catalog_asset_ids[file]\n",
    "    print(file,  catalog_asset_id)\n",
    "    #### \n",
    "    payload={\"name\": \"column_info\",\n",
    "       \"entity\":{\n",
    "                  #\"sample_size\":50\n",
    "               }\n",
    "    }\n",
    "    t=requests.post(host+\"v2/assets/\"+catalog_asset_id+\"/attributes?catalog_id=\"+catalog_id,json=payload,headers=headers,verify=False)\n",
    "    #print(t.text)\n",
    "    # For each column header in the file map its corresponding business term retrieved from the above join in the dataframe\n",
    "\n",
    "    i=0\n",
    "    for index, rows in Terms_Headers_new.iterrows(): \n",
    "        i+=1\n",
    "        print(i,rows.Column_header.strip(), \"is mapped to\", rows['Business Terms'])\n",
    "        # Create list for the current row \n",
    "        # Below payload is used for the patch request to map the  header to business terms\n",
    "        payload=[{\"op\":\"add\",\"path\":\"/\"+rows.Column_header.strip(),\"value\":{\"column_terms\":[{\"term_display_name\":rows['Business Terms'],\"term_id\":rows[\"entity.artifacts.global_id\"]}]},\"attribute\":\"column_info\"}]\n",
    "    #\n",
    "        # Endpoint for patch request\n",
    "        url=host+\"v2/assets/\"+catalog_asset_id+\"/attributes/column_info?catalog_id=\"+catalog_id\n",
    "    # patch request to map busines terms to column header using term_id\n",
    "        patch_attribute=s.patch(url,json=payload,headers=headers,verify=False)\n",
    "    #\n",
    "        json.loads(patch_attribute.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specified dataset is now published to the catalog and its column headers are mapped to their associated business terms. \n",
    "\n",
    "Navigate to below path to verify the mappings created above. <br>\n",
    "\n",
    "**All Catalogs --> New Catalog --> csv file --> any column header from the above list**.\n",
    "\n",
    "The associated business term for the column header is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
